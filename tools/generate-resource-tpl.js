import inflect from "inflect";
import { v2Resources } from "./v2-migration-utils";

function forceMapFor(name) {
  return (
    name.match(/_(params|attributes)$/) &&
    ![
      "resolution_rule_attributes",
      "alert_template_attributes",
      "sourceable_attributes",
    ].includes(name)
  );
}

module.exports = (name, resourceSchema, requiredFields, pathIdField) => {
  const nameCamel = inflect.camelize(name);
  const needsStrconv = name === "override_shift";
  const needsStrings = name === "override_shift";

  return `// DO NOT MODIFY: This file is generated by tools/generate.js. Any changes will be overwritten during the next build.

package provider

import (
	"context"
	"errors"
	"fmt"
	${needsStrings ? '"strings"' : ''}
	"github.com/hashicorp/terraform-plugin-log/tflog"
	"github.com/hashicorp/terraform-plugin-sdk/v2/diag"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/structure"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/validation"
	"github.com/rootlyhq/terraform-provider-rootly/v2/client"
	"github.com/rootlyhq/terraform-provider-rootly/v2/internal/converter"
	"github.com/rootlyhq/terraform-provider-rootly/v2/internal/diffsuppressfunc"
	"github.com/rootlyhq/terraform-provider-rootly/v2/tools"
	${needsStrconv ? '"strconv"' : ''}
)

func resource${nameCamel}() *schema.Resource {
	return &schema.Resource{
		CreateContext: resource${nameCamel}Create,
		ReadContext: resource${nameCamel}Read,
		${name === 'override_shift' ? '// UpdateContext omitted - all fields are ForceNew (UPDATE endpoint returns 404)' : 'UpdateContext: resource' + nameCamel + 'Update,'}
		DeleteContext: resource${nameCamel}Delete,
		Importer: &schema.ResourceImporter {
			StateContext: ${name === 'override_shift' ? 'resource' + nameCamel + 'Import' : 'schema.ImportStatePassthroughContext'},
		},
		Schema: map[string]*schema.Schema {
			${schemaFields(name, resourceSchema, requiredFields, pathIdField)}
		},
	}
}

${name === 'override_shift' ? generateOverrideShiftCreate(nameCamel, name, resourceSchema) : `func resource${nameCamel}Create(ctx context.Context, d *schema.ResourceData, meta interface{}) diag.Diagnostics {
	c := meta.(*client.Client)

	tflog.Trace(ctx, fmt.Sprintf("Creating ${nameCamel}"))

	s := &client.${nameCamel}{}

	${createResourceFields(name, resourceSchema)}

	res, err := c.Create${nameCamel}(s)
	if err != nil {
		return diag.Errorf("Error creating ${name}: %s", err.Error())
	}

	d.SetId(res.ID)
	tflog.Trace(ctx, fmt.Sprintf("created a ${name} resource: %s", d.Id()))

	return resource${nameCamel}Read(ctx, d, meta)
}`}

${name === 'override_shift' ? generateOverrideShiftRead(nameCamel, name) : `func resource${nameCamel}Read(ctx context.Context, d *schema.ResourceData, meta interface{}) diag.Diagnostics {
	c := meta.(*client.Client)
	tflog.Trace(ctx, fmt.Sprintf("Reading ${nameCamel}: %s", d.Id()))

	item, err := c.Get${nameCamel}(d.Id())
	if err != nil {
		// In the case of a NotFoundError, it means the resource may have been removed upstream
		// We just remove it from the state.
		if errors.Is(err, client.NewNotFoundError("")) && !d.IsNewResource() {
			tflog.Warn(ctx, fmt.Sprintf("${nameCamel} (%s) not found, removing from state", d.Id()))
			d.SetId("")
			return nil
		}

		return diag.Errorf("Error reading ${name}: %s", d.Id())
	}

	${setResourceFields(name, resourceSchema)}

	return nil
}`}

${name === 'override_shift' ? '' : `func resource${nameCamel}Update(ctx context.Context, d *schema.ResourceData, meta interface{}) diag.Diagnostics {
	c := meta.(*client.Client)
	tflog.Trace(ctx, fmt.Sprintf("Updating ${nameCamel}: %s", d.Id()))

	s := &client.${nameCamel}{}

	${updateResourceFields(name, resourceSchema)}

	_, err := c.Update${nameCamel}(d.Id(), s)
	if err != nil {
		return diag.Errorf("Error updating ${name}: %s", err.Error())
	}

	return resource${nameCamel}Read(ctx, d, meta)
}
`}
${name === 'override_shift' ? generateOverrideShiftDelete(nameCamel) : `func resource${nameCamel}Delete(ctx context.Context, d *schema.ResourceData, meta interface{}) diag.Diagnostics {
	c := meta.(*client.Client)
	tflog.Trace(ctx, fmt.Sprintf("Deleting ${nameCamel}: %s", d.Id()))

	err := c.Delete${nameCamel}(d.Id())
	if err != nil {
		// In the case of a NotFoundError, it means the resource may have been removed upstream.
		// We just remove it from the state.
		if errors.Is(err, client.NewNotFoundError("")) && !d.IsNewResource() {
			tflog.Warn(ctx, fmt.Sprintf("${nameCamel} (%s) not found, removing from state", d.Id()))
			d.SetId("")
			return nil
		}
		return diag.Errorf("Error deleting ${name}: %s", err.Error())
	}

	d.SetId("")

	return nil
}`}

${name === 'override_shift' ? generateOverrideShiftImport(nameCamel) : ''}
`;
};

function excludeIgnoredProperties([field, schema]) {
  return field !== "created_at" && field !== "updated_at" && !schema.tf_ignore;
}

function setResourceFields(name, resourceSchema) {
  const isV2Resource = v2Resources.includes(name);

  return Object.entries(resourceSchema.properties)
    .filter(excludeIgnoredProperties)
    .map(([field]) => {
      const schema = resourceSchema.properties[field];

      // NEW
      if (isV2Resource) {
        if (["array", "object"].includes(schema.type)) {
          return `
          if v, err := converter.Expand(item.${inflect.camelize(
            field
          )}, resource${inflect.camelize(
            name
          )}().Schema["${field}"]); err == nil {
            d.Set("${field}", v)
          } else {
            return diag.Errorf("Error expanding ${field}: %s", err.Error())
          }
          `;
        } else {
          return `
          d.Set("${field}", item.${inflect.camelize(field)})
          `;
        }
      }

      // OLD
      if (
        schema.type == "array" &&
        schema.items &&
        schema.items.type == "object" &&
        schema.items.properties
      ) {
        return `
          if item.${inflect.camelize(field)} != nil {
              processed_items_${field} := make([]map[string]interface{}, 0)

              for _, c := range item.${inflect.camelize(field)} {
                  if rawItem, ok := c.(map[string]interface{}); ok {
                      // Create a new map with only the fields defined in the schema
                      processed_item_${field} := map[string]interface{}{
                          ${Object.keys(schema.items.properties)
                            .map((key) => `"${key}": rawItem["${key}"]`)
                            .join(",\n")},
                      }
                      processed_items_${field} = append(processed_items_${field}, processed_item_${field})
                  }
              }

              d.Set("${field}", processed_items_${field})
          } else {
              d.Set("${field}", nil)
          }
        `;
      } else if (
        schema.type == "object" &&
        schema.properties &&
        !forceMapFor(name)
      ) {
        return `singleton_list_${field} := make([]interface{}, 1, 1)
          processed_item_${field} := map[string]interface{}{
            ${Object.keys(schema.properties)
              .map(
                (key) => `"${key}": item.${inflect.camelize(field)}["${key}"]`
              )
              .join(",\n")},
          }
          singleton_list_${field}[0] = processed_item_${field}
          d.Set("${field}", singleton_list_${field})
        `;
      }
      return `d.Set("${field}", item.${inflect.camelize(field)})`;
    })
    .join("\n  ");
}

function createResourceFields(name, resourceSchema) {
  const isV2Resource = v2Resources.includes(name);

  return Object.entries(resourceSchema.properties)
    .filter(excludeIgnoredProperties)
    .map(([field]) => {
      const schema = resourceSchema.properties[field];

      // NEW
      if (isV2Resource) {
        if (["array", "object"].includes(schema.type)) {
          return `
          if value, ok := d.GetOkExists("${field}"); ok {
            flattened, err := converter.Flatten(value, resource${inflect.camelize(
              name
            )}().Schema["${field}"])
            if err != nil {
              return diag.Errorf("Error flattening ${field}: %s", err.Error())
            }

            if flattened, ok := flattened.(map[string]any); ok {
              s.${inflect.camelize(field)} = flattened
            }
          }
          `;
        } else if (schema.type === "boolean") {
          return `
          if value, ok := d.GetOkExists("${field}"); ok {
            s.${inflect.camelize(field)} = tools.Bool(value.(${jsonapiToGoType(
            schema.type
          )}))
          }`;
        } else {
          return `
          if value, ok := d.GetOkExists("${field}"); ok {
            s.${inflect.camelize(field)} = value.(${jsonapiToGoType(
            schema.type
          )})
          }
          `;
        }
      }

      // OLD
      if (schema.type === "boolean") {
        return `  if value, ok := d.GetOkExists("${field}"); ok {
				s.${inflect.camelize(field)} = tools.Bool(value.(${jsonapiToGoType(
          schema.type
        )}))
			}`;
      } else if (
        schema.type == "object" &&
        schema.properties &&
        !forceMapFor(name)
      ) {
        return `  if value, ok := d.GetOkExists("${field}"); ok {
				if valueList, ok := value.([]interface{}); ok && len(valueList) > 0 && valueList[0] != nil {
          if mapValue, ok := valueList[0].(map[string]interface{}); ok {
            s.${inflect.camelize(field)} = mapValue
          }
        }
			}`;
      } else {
        return `  if value, ok := d.GetOkExists("${field}"); ok {
				s.${inflect.camelize(field)} = value.(${jsonapiToGoType(schema.type)})
			}`;
      }
    })
    .join("\n  ");
}

function updateResourceFields(name, resourceSchema) {
  const isV2Resource = v2Resources.includes(name);

  return Object.entries(resourceSchema.properties)
    .filter(excludeIgnoredProperties)
    .map(([field]) => {
      const schema = resourceSchema.properties[field];

      // NEW
      if (isV2Resource) {
        if (["array", "object"].includes(schema.type)) {
          return `
          if d.HasChange("${field}") {
            flattened, err := converter.Flatten(d.Get("${field}"), resource${inflect.camelize(
            name
          )}().Schema["${field}"])
            if err != nil {
              return diag.Errorf("Error flattening ${field}: %s", err.Error())
            }

            if flattened, ok := flattened.(map[string]any); ok {
              s.${inflect.camelize(field)} = flattened
            }
          }
          `;
        } else if (schema.type === "boolean") {
          return `
          if d.HasChange("${field}") {
            s.${inflect.camelize(
              field
            )} = tools.Bool(d.Get("${field}").(${jsonapiToGoType(schema.type)}))
          }`;
        } else if (schema.tf_include_unchanged) {
          return `
          s.${inflect.camelize(field)} = d.Get("${field}").(${jsonapiToGoType(
            schema.type
          )})
          `;
        } else {
          return `
          if d.HasChange("${field}") {
            s.${inflect.camelize(field)} = d.Get("${field}").(${jsonapiToGoType(
            schema.type
          )})
          }`;
        }
      }

      // OLD
      if (schema.type === "boolean") {
        return `  if d.HasChange("${field}") {
				s.${inflect.camelize(field)} = tools.Bool(d.Get("${field}").(${jsonapiToGoType(
          schema.type
        )}))
			}`;
      } else if (schema.type == "array") {
        return `
          if d.HasChange("${field}") {
            if value, ok := d.GetOk("${field}"); value != nil && ok {
              s.${inflect.camelize(field)} = value.([]interface{})
            } else {
              s.${inflect.camelize(field)} = []interface{}{}
            }
          }
			`;
      } else if (
        schema.type == "object" &&
        schema.properties &&
        !forceMapFor(name)
      ) {
        return `  if d.HasChange("${field}") {
      		tps := d.Get("${field}").([]interface{})
      		for _, tpsi := range tps {
      			s.${inflect.camelize(field)} = tpsi.(map[string]interface{})
      		}
      	}
			`;
      } else if (schema.tf_include_unchanged) {
        return `
				s.${inflect.camelize(field)} = d.Get("${field}").(${jsonapiToGoType(
          schema.type
        )})
			`;
      } else {
        return `  if d.HasChange("${field}") {
				s.${inflect.camelize(field)} = d.Get("${field}").(${jsonapiToGoType(
          schema.type
        )})
			}`;
      }
    })
    .join("\n  ");
}

function jsonapiToGoType(type) {
  switch (type) {
    case "string":
      return "string";
    case "integer":
      return "int";
    case "number":
      return "float32";
    case "boolean":
      return "bool";
    case "array":
      return "[]interface{}";
    case "object":
      return "map[string]interface{}";
    default:
      return "interface{}";
  }
}

function schemaFields(resourceName, resourceSchema, requiredFields, pathIdField) {
  return Object.entries(resourceSchema.properties)
    .filter(excludeIgnoredProperties)
    .map(([field]) => {
      return schemaField(resourceName, field, resourceSchema, requiredFields, pathIdField);
    })
    .join("\n");
}

function annotatedDescription(schema) {
  const description = (schema.description || "").replace(/"/g, '\\"');
  if (schema.enum) {
    return `${
      !!description ? `${description}. ` : ""
    }Value must be one of ${schema.enum
      .map((val) => `\`${val}\``)
      .join(", ")}.`;
  }
  if (
    schema.type === "object" &&
    schema.properties &&
    schema.properties.id &&
    schema.properties.name
  ) {
    return `Map must contain two fields, \`id\` and \`name\`. ${description}`;
  }
  if (schema.type === "array" && schema.items && schema.items.enum) {
    return `${
      !!description ? `${description}. ` : ""
    }Value must be one of ${schema.items.enum
      .map((val) => `\`${val}\``)
      .join(", ")}.`;
  }

  if (schema.type === "boolean") {
    return `${
      !!description ? `${description}. ` : ""
    }Value must be one of true or false`;
  }
  return description;
}

function generateValidateFunc(schema) {
  if (schema.enum && schema.enum.length > 0) {
    const enumValues = schema.enum.map((val) => `"${val}"`).join(", ");
    return `
		ValidateFunc: validation.StringInSlice([]string{${enumValues}}, false),`;
  }
  if (
    schema.type === "array" &&
    schema.items &&
    schema.items.enum &&
    schema.items.enum.length > 0
  ) {
    const enumValues = schema.items.enum.map((val) => `"${val}"`).join(", ");
    return `
		ValidateFunc: validation.StringInSlice([]string{${enumValues}}, false),`;
  }
  return "";
}

function schemaField(resourceName, name, resourceSchema, requiredFields, pathIdField) {
  const schema = resourceSchema.properties[name];
  const optional =
    (requiredFields || []).indexOf(name) === -1 || schema.enum
      ? "true"
      : "false";
  const required =
    (requiredFields || []).indexOf(name) === -1 || schema.enum
      ? "false"
      : "true";
  let defaultValue;
  if (schema.default) {
    defaultValue = `Default: "${schema.default}"`;
  } else if (
    schema.enum &&
    schema.enum.length > 0 &&
    !schema.anyOfChild &&
    name !== "status"
  ) {
    defaultValue = `Default: "${schema.enum[0]}"`;
  } else if (schema.tf_computed === false) {
    defaultValue = `Default: nil,\n				Computed: false`;
  } else {
    defaultValue = `Computed: ${optional}`;
  }
  const description = annotatedDescription(schema);
  const sensitive = schema.tf_sensitive ? "true" : "false";
  // For override_shift, all fields must be ForceNew because UPDATE endpoint is broken (returns 404)
  const forceNew =
    name === pathIdField || schema.tf_force_new || (resourceName === 'override_shift') ? "true" : "false";
  const writeOnly = schema.tf_write_only ? "true" : "false";

  const diffSuppressFunc = schema.tf_diff_suppress_func
    ? schema.tf_diff_suppress_func
    : schema.tf_skip_diff // TODO: Change the spec to emit {"tf_diff_suppress_func": "diffsuppressfunc.Skip"} instead of {"tf_skip_diff": true}
    ? "diffsuppressfunc.Skip"
    : null;
  const diffSuppressFuncField = diffSuppressFunc
    ? `\nDiffSuppressFunc: ${diffSuppressFunc},`
    : "";

  const stateFunc = schema.accepts_unordered
    ? `
		StateFunc: func(v interface{}) string {
			json, _ := structure.NormalizeJsonString(v)
			return json
		},
	`
    : "";
  const validateFunc = generateValidateFunc(schema);
  switch (schema.type) {
    case "string":
      return `
			"${name}": &schema.Schema {
				Type: schema.TypeString,
				${defaultValue},
				Required: ${required},
				Optional: ${optional},
        Sensitive: ${sensitive},
				ForceNew: ${forceNew},
        WriteOnly: ${writeOnly},
				Description: "${description}",${validateFunc}${diffSuppressFuncField}
			},
			`;
    case "integer":
      return `
      "${name}": &schema.Schema {
        Type: schema.TypeInt,
        Computed: ${optional},
        Required: ${required},
        Optional: ${optional},
        Sensitive: ${sensitive},
        ForceNew: ${forceNew},
        WriteOnly: ${writeOnly},
        Description: "${description}",
        ${diffSuppressFuncField}
      },
      `;
    case "number":
      return `
			"${name}": &schema.Schema {
				Type: schema.TypeFloat,
				Computed: ${optional},
				Required: ${required},
				Optional: ${optional},
        Sensitive: ${sensitive},
				ForceNew: ${forceNew},
        WriteOnly: ${writeOnly},
				Description: "${description}",
				${diffSuppressFuncField}
			},
			`;
    case "boolean":
      if (name === "enabled") {
        return `
				"${name}": &schema.Schema {
					Type: schema.TypeBool,
					Default: true,
					Optional: true,
          Sensitive: ${sensitive},
          ForceNew: ${forceNew},
          WriteOnly: ${writeOnly},
					${diffSuppressFuncField}
				},
				`;
      }
      return `
        "${name}": &schema.Schema {
          Type: schema.TypeBool,
          Computed: ${optional},
          Required: ${required},
          Optional: ${optional},
          Sensitive: ${sensitive},
          ForceNew: ${forceNew},
          WriteOnly: ${writeOnly},
          Description: "${description}",
          ${diffSuppressFuncField}
        },
        `;
    case "array":
      if (
        schema.items &&
        schema.items.type === "object" &&
        schema.items.properties
      ) {
        return `
				"${name}": &schema.Schema {
					Type: schema.TypeList,
					Computed: ${schema.tf_computed ? "true" : "false"},
					Required: ${required},
					Optional: ${optional},
          Sensitive: ${sensitive},
          ForceNew: ${forceNew},
          WriteOnly: ${writeOnly},
					Description: "${description}",
					DiffSuppressFunc: tools.EqualIgnoringOrder,
					Elem: &schema.Resource {
						Schema: map[string]*schema.Schema {
              ${Object.keys(schema.items.properties)
                .map((key) => {
                  return schemaField(resourceName, key, schema.items, [], pathIdField);
                })
                .join("\n")}
						},
					},
					${stateFunc}
				},
				`;
      } else if (schema.items && schema.items.type === "string") {
        const elemValidateFunc =
          schema.items.enum && schema.items.enum.length > 0
            ? `\n\t\t\t\t\tValidateFunc: validation.StringInSlice([]string{${schema.items.enum
                .map((val) => `"${val}"`)
                .join(", ")}}, false),`
            : "";
        return `
				"${name}": &schema.Schema {
					Type: schema.TypeList,
					Elem: &schema.Schema {
						Type: schema.TypeString,${elemValidateFunc}
					},
					DiffSuppressFunc: tools.EqualIgnoringOrder,
					Computed: ${schema.tf_computed ? "true" : "false"},
					Required: ${required},
					Optional: ${optional},
          Sensitive: ${sensitive},
          ForceNew: ${forceNew},
          WriteOnly: ${writeOnly},
					Description: "${description}",
					${stateFunc}
				},
				`;
      } else if (schema.items && schema.items.type === "number") {
        return `
				"${name}": &schema.Schema {
					Type: schema.TypeList,
					Elem: &schema.Schema {
						Type: schema.TypeInt,
					},
					DiffSuppressFunc: tools.EqualIgnoringOrder,
					Computed: ${schema.tf_computed ? "true" : "false"},
					Required: ${required},
					Optional: ${optional},
          Sensitive: ${sensitive},
          ForceNew: ${forceNew},
          WriteOnly: ${writeOnly},
					Description: "${description}",
					${stateFunc}
				},
				`;
      } else if (schema.items && schema.items.type === "integer") {
        return `
				"${name}": &schema.Schema {
					Type: schema.TypeList,
					Elem: &schema.Schema {
						Type: schema.TypeInt,
					},
					DiffSuppressFunc: tools.EqualIgnoringOrder,
					Computed: ${schema.tf_computed ? "true" : "false"},
					Required: ${required},
					Optional: ${optional},
          Sensitive: ${sensitive},
          ForceNew: ${forceNew},
          WriteOnly: ${writeOnly},
					Description: "${description}",
					${stateFunc}
				},
				`;
      } else {
        console.log(`unsupported array field schema:`, name, schema);
        return "";
      }
    case "object":
    default:
      if (schema.properties && !forceMapFor(name)) {
        return `
   			"${name}": &schema.Schema {
	 				Type: schema.TypeList,
	 				Computed: ${optional},
	 				Required: ${required},
	 				Optional: ${optional},
          Sensitive: ${sensitive},
          ForceNew: ${forceNew},
          WriteOnly: ${writeOnly},
	 				Description: "${description}",
						MinItems: 0,
						MaxItems: 1,
	 					Elem: &schema.Resource {
							Schema: map[string]*schema.Schema {
	 							${Object.keys(schema.properties)
                  .map((key) => {
                    return schemaField(
                      resourceName,
                      key,
                      schema,
                      schema.required,
                      pathIdField
                    );
                  })
                  .join("\n")}
							},
	 					},
	 				},
   			`;
      }
      return `
			"${name}": &schema.Schema {
				Type: schema.TypeMap,
				Elem: &schema.Schema {
					Type: schema.TypeString,
				},
				Computed:    ${optional},
				Required:    ${required},
				Optional:    ${optional},
				Sensitive:   ${sensitive},
				ForceNew:    ${forceNew},
				WriteOnly:   ${writeOnly},
				Description: "${description}",
			},
			`;
  }
}

// Custom generator functions for override_shift (broken API endpoints workarounds)
function generateOverrideShiftCreate(nameCamel, name, resourceSchema) {
  const createFields = createResourceFields(name, resourceSchema);
  return `func resource${nameCamel}Create(ctx context.Context, d *schema.ResourceData, meta interface{}) diag.Diagnostics {
	c := meta.(*client.Client)
	tflog.Trace(ctx, fmt.Sprintf("Creating ${nameCamel}"))

	s := &client.${nameCamel}{}

	${createFields.replace(/if value, ok := d\.GetOkExists\("user"\); ok \{\s*s\.User = value\.\(map\[string\]interface\{\}\)\s*\}/s, 
		`if value, ok := d.GetOkExists("user"); ok {
		if userMap, ok := value.(map[string]interface{}); ok {
			if userIdStr, ok := userMap["id"].(string); ok {
				if userId, err := strconv.Atoi(userIdStr); err == nil {
					s.UserId = userId
				}
			}
		}
	}`)}

	res, err := c.Create${nameCamel}(s)
	if err != nil {
		return diag.Errorf("Error creating override_shift: %s", err.Error())
	}

	d.SetId(res.ID)
	tflog.Trace(ctx, fmt.Sprintf("created a override_shift resource: %s", d.Id()))

	// Set the attributes from the CREATE response directly instead of calling Read
	// because override_shifts don't have a working GET endpoint
	d.Set("schedule_id", res.ScheduleId)
	d.Set("rotation_id", res.RotationId)
	// Keep the original config values for starts_at and ends_at to avoid timezone drift
	d.Set("starts_at", d.Get("starts_at"))
	d.Set("ends_at", d.Get("ends_at"))
	d.Set("is_override", res.IsOverride)
	d.Set("shift_override", res.ShiftOverride)
	// Keep the original config value for user to avoid format drift
	d.Set("user", d.Get("user"))

	return nil
}`;
}

function generateOverrideShiftRead(nameCamel, name) {
  return `func resource${nameCamel}Read(ctx context.Context, d *schema.ResourceData, meta interface{}) diag.Diagnostics {
	c := meta.(*client.Client)
	shiftId := d.Id()
	tflog.Trace(ctx, fmt.Sprintf("Reading ${nameCamel}: %s", shiftId))

	// Override shifts don't have a working GET endpoint in the Rootly API
	// The /v1/override_shifts/{id} endpoint returns 404 even for valid shifts
	// We need to use the LIST endpoint: /v1/schedules/{schedule_id}/override_shifts
	scheduleId, ok := d.GetOk("schedule_id")
	if !ok || scheduleId == "" {
		tflog.Warn(ctx, fmt.Sprintf("Cannot refresh ${nameCamel} %s without schedule_id", shiftId))
		return nil
	}

	// List all override shifts for this schedule (pagination handled by client)
	shiftsInterface, err := c.List${nameCamel}s(scheduleId.(string), nil)
	if err != nil {
		return diag.Errorf("Error listing override_shifts for schedule %s: %s", scheduleId, err.Error())
	}

	// Find the shift with matching ID
	var shift *client.${nameCamel}
	for _, shiftInterface := range shiftsInterface {
		s := shiftInterface.(*client.${nameCamel})
		if s.ID == shiftId {
			shift = s
			break
		}
	}

	if shift == nil {
		tflog.Warn(ctx, fmt.Sprintf("${nameCamel} %s not found, removing from state", shiftId))
		d.SetId("")
		return nil
	}

	// Populate state from the shift data
	d.Set("schedule_id", shift.ScheduleId)
	d.Set("rotation_id", shift.RotationId)
	d.Set("starts_at", shift.StartsAt)
	d.Set("ends_at", shift.EndsAt)
	d.Set("is_override", shift.IsOverride)
	d.Set("shift_override", shift.ShiftOverride)
	
	// Convert User object to map for Terraform state
	if shift.User != nil {
		userMap := map[string]interface{}{
			"id": shift.User.ID,
		}
		d.Set("user", userMap)
	}

	return nil
}`;
}

function generateOverrideShiftDelete(nameCamel) {
  return `func resource${nameCamel}Delete(ctx context.Context, d *schema.ResourceData, meta interface{}) diag.Diagnostics {
	tflog.Trace(ctx, fmt.Sprintf("Deleting ${nameCamel}: %s", d.Id()))
	
	// WARNING: The Rootly API does not have a working DELETE endpoint for override shifts
	// The /v1/override_shifts/{id} endpoint returns 404 even for valid shifts
	// This means the shift will remain in Rootly and must be manually deleted via the UI
	tflog.Warn(ctx, fmt.Sprintf("Override shift %s removed from Terraform state but still exists in Rootly (DELETE endpoint not available). Please manually delete from Rootly UI if needed.", d.Id()))
	
	// Remove from state anyway
	d.SetId("")
	
	return diag.Diagnostics{
		diag.Diagnostic{
			Severity: diag.Warning,
			Summary:  "Override shift removed from state only",
			Detail:   fmt.Sprintf("Override shift %s has been removed from Terraform state, but the DELETE API endpoint is not available. The shift still exists in Rootly and must be manually deleted via the Rootly UI at https://rootly.com/schedules.", d.Id()),
		},
	}
}`;
}

function generateOverrideShiftImport(nameCamel) {
  return `
// Custom import function for override shifts
// Format: {schedule_id}:{shift_id}
func resource${nameCamel}Import(ctx context.Context, d *schema.ResourceData, meta interface{}) ([]*schema.ResourceData, error) {
	importId := d.Id()

	parts := strings.Split(importId, ":")
	if len(parts) != 2 {
		return nil, fmt.Errorf("invalid import ID format. Use: {schedule_id}:{shift_id}")
	}

	scheduleId := parts[0]
	shiftId := parts[1]

	// Set the schedule_id in state so Read can use it
	d.Set("schedule_id", scheduleId)
	d.SetId(shiftId)

	// Call Read to populate the rest of the state
	diags := resource${nameCamel}Read(ctx, d, meta)
	if diags.HasError() {
		return nil, fmt.Errorf("failed to read override shift: %v", diags)
	}

	if d.Id() == "" {
		return nil, fmt.Errorf("override shift %s not found in schedule %s", shiftId, scheduleId)
	}

	return []*schema.ResourceData{d}, nil
}`;
}
